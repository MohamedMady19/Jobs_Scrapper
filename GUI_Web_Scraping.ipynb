{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8103fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6f2cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page num 179\n",
      "15\n",
      "1\n",
      "Page switched\n",
      "page num 179\n",
      "15\n",
      "2\n",
      "Page switched\n",
      "page num 179\n",
      "15\n",
      "3\n",
      "Page switched\n",
      "page num 179\n",
      "endeed\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "Window = Tk()\n",
    "Window.geometry('600x300')\n",
    "Window.title(\"Jobs Scrapper\")\n",
    "Window.resizable(False , False)\n",
    "Window.config(background='whitesmoke')\n",
    "\n",
    "job = StringVar()\n",
    "Num_Pages = StringVar()\n",
    "df  = \"\" \n",
    "\n",
    "Job_Title = Label(text = \"Job Title\" , font = (\"Arial\" , 13) ,bg = 'silver', fg = 'red')\n",
    "Job_Title.place(x = 115 , y = 50)\n",
    "\n",
    "ent = Entry(width = '25'  ,textvariable = job)\n",
    "ent.place(x = 300 , y = 50)\n",
    "\n",
    "NP = Label(text = \"No. of Pages\" , font = (\"Arial\" , 13) ,bg = 'silver', fg = 'red')\n",
    "NP.place(x = 100 , y = 100)\n",
    "\n",
    "ent = Entry(width = '25' , textvariable =Num_Pages )\n",
    "ent.place(x = 300 , y = 100)\n",
    "\n",
    "def Scrap():\n",
    "    \n",
    "    job_name = job.get()\n",
    "    number_of_pages = Num_Pages.get()\n",
    "    \n",
    "    titles=[]\n",
    "    company=[]\n",
    "    location=[]\n",
    "    skill=[]\n",
    "    country=[]\n",
    "    new_location=[]\n",
    "    final_loc=[]\n",
    "    work_hours=[]\n",
    "    City=[]\n",
    "    Governorate=[]\n",
    "    final_skill=[]\n",
    "    experience=[]\n",
    "    experience_years=[]\n",
    "    skill2=[]\n",
    "    links=[]\n",
    "    label=[]\n",
    "    education_level=[]\n",
    "    vacancies=[]\n",
    "    num=0\n",
    "    job_name=job_name.lower()\n",
    "    name=job_name.split(' ')\n",
    "    number_of_pages=int(number_of_pages)-1\n",
    "\n",
    "    url='https://wuzzuf.net/search/jobs/?a=navbg&q='+str(name[0])+'%20'+str(name[1])+'&start='+str(num)\n",
    "    result=requests.get(url)\n",
    "    src=result.content\n",
    "    soup=BeautifulSoup(src,'lxml')\n",
    "    maximum_page=int(soup.find('strong').text)\n",
    "    if(int(number_of_pages)>maximum_page//15):\n",
    "        print('Sorry,Limited Pages,maximum pages you can get is ',(maximum_page//15)+1)\n",
    "    else:\n",
    "        while True:\n",
    "            \n",
    "\n",
    "            print('page num',maximum_page)\n",
    "            if(num>int(number_of_pages)):\n",
    "                print('endeed')\n",
    "                break\n",
    "            job_titles=soup.find_all('h2',{'class':'css-m604qf'})\n",
    "            company_names=soup.find_all('a',{'class':'css-17s97q8'})\n",
    "            locations=soup.find_all('span',{'class':'css-5wys0k'})\n",
    "            time=soup.find_all('div',{'class':'css-1lh32fc'})\n",
    "            skill_descr=soup.find_all('div',{'class':'css-y4udm8'})\n",
    "            print(len(job_titles))\n",
    "            for j in range (len(job_titles)):\n",
    "                titles.append(job_titles[j].text)\n",
    "                links.append('https://wuzzuf.net/'+job_titles[j].find('a').attrs['href'])\n",
    "                company.append(company_names[j].text[:-2])\n",
    "                location.append(locations[j].text)\n",
    "                work_hours.append(time[j].text)\n",
    "                skill.append(skill_descr[j].text)\n",
    "                label.append(job_name)\n",
    "            num+=1\n",
    "            print(num)\n",
    "            print('Page switched')\n",
    "        for link in links:\n",
    "\n",
    "            try:\n",
    "                headers = {\n",
    "                        \"Connection\": \"keep-alive\",\n",
    "                        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/537.36\",\n",
    "                    }\n",
    "                result2=requests.get(link,headers=headers,timeout=5)\n",
    "                src2=result2.content\n",
    "                soup2=BeautifulSoup(src2,'lxml')\n",
    "                description=soup2.find(\"span\", attrs={\"itemprop\": \"description\"})\n",
    "                edu_level=soup2.find(\"dd\", attrs={\"class\": \"requirement-content\"})\n",
    "                education_level.append(edu_level.text)\n",
    "                print(\"Done\")\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            \n",
    "        for i in range (len(location)):\n",
    "                country.append(location[i].split(',')[-1])\n",
    "                new_location.append(location[i].split(',')[:-1])\n",
    "        for i in range(len(new_location)):\n",
    "            final_loc.append(' '.join(new_location[i]))\n",
    "        \n",
    "        for i in range(len(skill)):\n",
    "            skill[i]=skill[i].lstrip(work_hours[i])\n",
    "        \n",
    "        for i in range (len(titles)):\n",
    "            skill[i].split('路')\n",
    "            skill[i]=skill[i].replace('Yrs of Exp','')\n",
    "            experience.append(skill[i].split('路')[0].strip())\n",
    "            experience_years.append(skill[i].strip().split('路')[1])\n",
    "            skill2.append(skill[i].split('路')[2:])\n",
    "        for i in range(len(new_location)):\n",
    "            final_skill.append(' '.join(skill2[i]))\n",
    "            if(len(location[i].split(','))==2):\n",
    "                City.append('No City avaliable')\n",
    "                Governorate.append(location[i].split(',')[0].strip())\n",
    "            else:\n",
    "                City.append(location[i].split(',')[0].strip())\n",
    "                Governorate.append(location[i].split(',')[1].strip())\n",
    "                \n",
    "        global  df        \n",
    "        df=pd.DataFrame({'Job Name': label, 'Job Title': titles, 'Company Name': company,'Area': City,\n",
    "                         'Governorate': Governorate, 'Country': country, 'Work Type': work_hours,\n",
    "                         'Experience level': experience, 'Experience in Years': experience_years, 'skills': final_skill})\n",
    "        messagebox.showinfo(\"Done\" )\n",
    "        return df\n",
    "\n",
    "\n",
    "def Save ():\n",
    "    global  df        \n",
    "    df.to_csv('Jobs.csv',index=False)\n",
    "    print(\"OK\")\n",
    "\n",
    "\n",
    "bt1 = Button(text = \"Find\" , font = (\"Arial\", 15), bg = 'silver' , fg = 'green', width = '8', command = Scrap )\n",
    "bt1.place(x = 300 , y = 150)\n",
    "\n",
    "bt2 = Button(text = \"Download\", font = (\"Arial\", 15), bg = 'silver', fg = 'blue', width = '8'  , command = Save)\n",
    "bt2.place(x = 420 , y = 150)\n",
    "\n",
    "Window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f64ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
